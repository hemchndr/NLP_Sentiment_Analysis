{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7dce94cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9784fe8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9727609",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_path = r\"C:\\Users\\hemch\\Downloads\\Healthcare Projects\\Dataset.csv\"\n",
    "data = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd7bc829",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review_Text</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have mixed feelings about my experience.</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The staff was caring and attentive. I couldn't...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I have mixed feelings about my experience.</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I have mixed feelings about my experience.</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The healthcare provider was excellent. I had a...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Review_Text  Rating\n",
       "0        I have mixed feelings about my experience.        4\n",
       "1  The staff was caring and attentive. I couldn't...       5\n",
       "2        I have mixed feelings about my experience.        5\n",
       "3        I have mixed feelings about my experience.        5\n",
       "4  The healthcare provider was excellent. I had a...       3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1ec6c5",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "**Text Cleaning**: Tokenization, stop-word removal, and lemmatization.\n",
    "\n",
    "**Data Transformation**: Converting text data into a suitable format for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8be6264a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure all review text entries are strings\n",
    "data['Review_Text'] = data['Review_Text'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b2bba0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text_sklearn(text):\n",
    "    # Remove special characters and digits\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text, re.I|re.A)\n",
    "    text = text.lower()\n",
    "    text = text.strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b33dbabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Cleaned_Review'] = data['Review_Text'].apply(preprocess_text_sklearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895c5579",
   "metadata": {},
   "source": [
    "## Sentiment Labeling\n",
    "\n",
    "**Define Sentiment Categories**: Based on the Rating column, categorize reviews into positive, negative, and neutral sentiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc25f0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_sentiment(rating):\n",
    "    if rating >= 4:\n",
    "        return 'positive'\n",
    "    elif rating == 3:\n",
    "        return 'neutral'\n",
    "    else:\n",
    "        return 'negative'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a65d1ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply sentiment labeling\n",
    "data['Sentiment'] = data['Rating'].apply(label_sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa60e16",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "**LOGISTIC REGRESSION MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc320aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data['Cleaned_Review'], data['Sentiment'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92c5dc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform Text Data into TF-IDF Features\n",
    "tfidf = TfidfVectorizer(max_features=5000, stop_words=ENGLISH_STOP_WORDS)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ef23526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the Logistic Regression Model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "748dd03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b2c0891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.38      0.39      0.38        77\n",
      "     neutral       0.00      0.00      0.00        35\n",
      "    positive       0.43      0.59      0.50        88\n",
      "\n",
      "    accuracy                           0.41       200\n",
      "   macro avg       0.27      0.33      0.29       200\n",
      "weighted avg       0.34      0.41      0.37       200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hemch\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\hemch\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\hemch\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_test, y_pred, target_names=['negative', 'neutral', 'positive'])\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3b810c",
   "metadata": {},
   "source": [
    "Insights:\n",
    "\n",
    "**Negative Sentiment:**\n",
    "\n",
    "Precision: 38%  \n",
    "Recall: 39%  \n",
    "F1-Score: 38%  \n",
    "\n",
    "\n",
    "**Neutral Sentiment:**\n",
    "\n",
    "Precision: 0%  \n",
    "Recall: 0%  \n",
    "F1-Score: 0%  \n",
    "\n",
    "\n",
    "**Positive Sentiment:**\n",
    "\n",
    "Precision: 43%  \n",
    "Recall: 59%  \n",
    "F1-Score: 50%  \n",
    "\n",
    "**Overall Accuracy: 41%**\n",
    "\n",
    "The model shows moderate performance in identifying negative and positive sentiments but struggles significantly with neutral sentiments, as indicated by the 0% precision and recall for neutral reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd59312",
   "metadata": {},
   "source": [
    "## Applying with multiple Models \n",
    "\n",
    "**Naive Bayes**\n",
    "\n",
    "**Support Vector Machine (SVM)**\n",
    "\n",
    "**Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e21d897",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "90e9c348",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b1d8ac11",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Naive Bayes': MultinomialNB(),\n",
    "    'Support Vector Machine': SVC(),\n",
    "    'Random Forest': RandomForestClassifier()\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "19b619c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Naive Bayes\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.39      0.34      0.36        77\n",
      "     neutral       0.00      0.00      0.00        35\n",
      "    positive       0.43      0.66      0.52        88\n",
      "\n",
      "    accuracy                           0.42       200\n",
      "   macro avg       0.28      0.33      0.30       200\n",
      "weighted avg       0.34      0.42      0.37       200\n",
      "\n",
      "Evaluating Support Vector Machine\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.38      0.39      0.38        77\n",
      "     neutral       0.00      0.00      0.00        35\n",
      "    positive       0.43      0.59      0.50        88\n",
      "\n",
      "    accuracy                           0.41       200\n",
      "   macro avg       0.27      0.33      0.29       200\n",
      "weighted avg       0.34      0.41      0.37       200\n",
      "\n",
      "Evaluating Random Forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.38      0.39      0.38        77\n",
      "     neutral       0.00      0.00      0.00        35\n",
      "    positive       0.43      0.59      0.50        88\n",
      "\n",
      "    accuracy                           0.41       200\n",
      "   macro avg       0.27      0.33      0.29       200\n",
      "weighted avg       0.34      0.41      0.37       200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hemch\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\hemch\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\hemch\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\hemch\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\hemch\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\hemch\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\hemch\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\hemch\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\hemch\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "for model_name, model in models.items():\n",
    "    print(f\"Evaluating {model_name}\")\n",
    "    model.fit(X_train_tfidf, y_train)\n",
    "    y_pred = model.predict(X_test_tfidf)\n",
    "    report = classification_report(y_test, y_pred, target_names=['negative', 'neutral', 'positive'])\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771b8984",
   "metadata": {},
   "source": [
    "Insights and Model Performance Comparison\n",
    "\n",
    "**Naive Bayes**\n",
    "\n",
    "Achieved the highest accuracy of 42%.  \n",
    "Performed best in predicting positive sentiments with an F1-score of 52%.  \n",
    "Struggled with neutral sentiments, similar to other models.  \n",
    "\n",
    "**SVM and Random Forest**\n",
    "\n",
    "All had an accuracy of 41%.  \n",
    "Showed similar performance metrics, with F1-scores of around 50% for positive sentiments.  \n",
    "Failed to effectively predict neutral sentiments  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70fa8ba",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "\n",
    "The sentiment analysis reveals a consistent challenge across all models in accurately predicting neutral sentiments. Positive sentiments were identified with moderate success, while negative sentiments had lower precision and recall. Among the models, Naive Bayes slightly outperformed the others in overall accuracy and the prediction of positive sentiments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3eeaaff",
   "metadata": {},
   "source": [
    "## Recommendations\n",
    "\n",
    "**Data Augmentation:**\n",
    "\n",
    "Increase the dataset size, especially for neutral reviews, to provide more balanced training data.  \n",
    "Collect more labeled data to improve model training.  \n",
    "\n",
    "**Advanced Models**\n",
    "\n",
    "Explore more sophisticated models such as BERT or other transformer-based models that might capture nuances better than traditional classifiers.  \n",
    "\n",
    "**Feature Engineering**\n",
    "\n",
    "Incorporate additional text processing techniques, such as n-grams (bigrams or trigrams) and word embeddings.  \n",
    "Experiment with different feature extraction methods and hyperparameter tuning.  \n",
    "\n",
    "**Continuous Improvement**\n",
    "\n",
    "Implement a feedback loop to continuously collect new patient reviews and update the analysis.  \n",
    "Regularly refine and retrain models with new data to improve accuracy and relevance.  \n",
    "\n",
    "**Summary**\n",
    "\n",
    "This sentiment analysis project provides a foundation for understanding patient feedback on healthcare services. Although the models showed moderate success in predicting sentiments, there is significant room for improvement. By following the recommendations, the analysis can be refined to provide more accurate and actionable insights, ultimately aiding healthcare providers in enhancing their services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b177330",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
